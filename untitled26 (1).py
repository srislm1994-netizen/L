# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12HANb9NjFae8KnoFEWbMgTcqUi8DMe4c
"""

# -- தேவையான Python நூலகங்கள் --
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import joblib
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, InputLayer

# -- SHAP explainability library --
try:
    import shap
except Exception:
    shap = None

# -- Dataset ஏற்றுதல் அல்லது உருவாக்குதல் --
def load_or_generate(csv_path=None):
    if csv_path and os.path.exists(csv_path):
        df = pd.read_csv(csv_path)
        print("Loaded CSV dataset.")
    else:
        print("Generating synthetic dataset.")
        length = 1000
        t = np.arange(length)
        df = pd.DataFrame({
            "feature1": np.sin(t * 0.02) + np.random.normal(0, 0.08, length),
            "feature2": np.cos(t * 0.015) + np.random.normal(0, 0.07, length),
            "feature3": np.sin(t * 0.01) * 0.5 + np.random.normal(0, 0.05, length),
            "target": 0.6 * np.sin(t * 0.02) + 0.4 * np.cos(t * 0.01) + np.random.normal(0, 0.03, length)
        })
    df = df.fillna(method="ffill").fillna(method="bfill")
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    target_col = "target" if "target" in numeric_cols else numeric_cols[-1]
    feature_cols = [c for c in numeric_cols if c != target_col]
    scaler = MinMaxScaler()
    scaled_df = pd.DataFrame(scaler.fit_transform(df[numeric_cols]), columns=numeric_cols)
    joblib.dump(scaler, "scaler.gz")
    return scaled_df, feature_cols, target_col, scaler, numeric_cols

# -- Data sequences LSTM format-இல் உருவாக்குதல் --
def make_sequences(data_array, seq_len, n_features, target_index):
    X, y = [], []
    for i in range(len(data_array) - seq_len):
        X.append(data_array[i:i + seq_len, :n_features])
        y.append(data_array[i + seq_len, target_index])
    return np.array(X), np.array(y)

# -- LSTM Neural Network அமைத்தல் --
def build_lstm_model(input_shape, units1=64, units2=32, dropout=0.2, lr=0.001):
    model = Sequential()
    model.add(InputLayer(input_shape=input_shape))
    model.add(LSTM(units1, return_sequences=True))
    model.add(Dropout(dropout))
    model.add(LSTM(units2))
    model.add(Dropout(dropout))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(1))
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    model.compile(optimizer=optimizer, loss='mse')
    return model

# -- Walk-forward validation (sliding window) --
def walk_forward_validation(model_builder, X, y, initial_train_size, window_stride=1):
    metrics = []
    n = len(X)
    i = initial_train_size
    while i < (n-1):
        X_train, y_train = X[:i], y[:i]
        X_val, y_val = X[i:i+1], y[i:i+1]
        model = model_builder()
        model.fit(X_train, y_train, epochs=10, verbose=0)
        y_pred = model.predict(X_val)
        mse = mean_squared_error(y_val, y_pred)
        mae = mean_absolute_error(y_val, y_pred)
        metrics.append((mse, mae))
        i += window_stride
        if len(metrics) > 30: break
    print("Completed", len(metrics), "rolling evaluations.")
    return metrics

# -- Multi-step forecasting (correct rolling sequence) --
def multi_step_forecast(model, last_sequence, steps):
    seq = last_sequence.copy()
    preds = []
    for _ in range(steps):
        pred = model.predict(seq.reshape(1, seq.shape[0], seq.shape[1]))[0, 0]
        preds.append(pred)
        seq = np.vstack([seq[1:], np.append(seq[-1, :-1], pred)])
    return np.array(preds)

# -- SHAP feature importance plot --
def shap_feature_importance(model, X_train):
    if shap is not None:
        try:
            sample_X = X_train[:100]
            explainer = shap.KernelExplainer(model.predict, sample_X)
            shap_values = explainer.shap_values(sample_X[:30])
            shap.summary_plot(shap_values, sample_X[:30], show=False)
            plt.savefig("shap_summary.png")
            print("SHAP summary saved.")
        except Exception as e:
            print("SHAP Error:", e)
    else:
        print("SHAP library not available.")

# -- Run all steps, example main flow --
CSV_PATH = ""   # உங்கள் dataset path (empty for synthetic)
data, feature_cols, target_col, scaler, numeric_cols = load_or_generate(CSV_PATH)
seq_len = 20
X, y = make_sequences(data.values, seq_len, len(feature_cols), data.columns.get_loc(target_col))
split_idx = int(0.8 * len(X))
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

model = build_lstm_model(input_shape=(seq_len, len(feature_cols)))
model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))
metrics = walk_forward_validation(lambda: build_lstm_model(input_shape=(seq_len, len(feature_cols))), X_train, y_train, initial_train_size=200)

last_seq = X_test[-1]
future_preds = multi_step_forecast(model, last_seq, steps=20)

shap_feature_importance(model, X_train)